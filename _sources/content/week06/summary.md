# Summary

## Principlism

Derived from medical ethics, the 4 *principles* of principlism are:
1. **Non-maleficence** (do no harm). Predict harm, avoid causing harm, minimize harm in both the short and long term.
2. **Beneficence** (do good). Anticipate and act to achieve good outcomes in both the short and long term.
3. **Respect Autonomy** (respect people's values, choices, *preferences*, and plans). Understand what others value, don't override their choices.
4. **Justice** (fairness). Distribute benefits and harms fairly. Implement fair processes, and don't unfairly discriminate.

In 2018, Luciano Floridi et al. propose an extension to the framework used in medical ethics so that principlism can be applied more effectively to AI. They add a 5th principle:
  
- **Explicability** (intelligibility, transparency, and accountability). Make it clear how the systems we implement work, and who is responsible for the way they work.

```{note}
I thought [this was a nice summary of Floridi's version of principlism](https://hdsr.mitpress.mit.edu/pub/l0jsh9d1), if you're interested in some extra reading.
```

## Fairness

Fairness, often considered interchangeably with *justice*, is critical to consider when evaluating AI systems. Fairness means:
- giving each person their due (what they deserve),
- treating similar cases similarly (being blind to arbitrary differences),
- treating people equally regardless of race, religion, class, sex, gender, sexual orientation, etc.
- equal consideration and respect for different beliefs and characters.

Fairness is important when:
- allocating social resources (**distributive justice**),
  - includes resources and opportunities
- implementing procedures that allocate benefits or harms (**procedural justice**),
  - eg. allocating scarce spaces at university, criminal sentencing
- determining penalties for wrongdoing (**retributive justice**),
- providing remediation/compensation for unfair treatment (**reparative justice**).

## Accountability

Accountability
: The state of being *accountable*. Accountability for AI systems requires answering for their failures and shortcomings, being responsible for blame, and providing an account for why the system exists in the way it does. Accountability often involves legal liability.

### Accountability for Reasonableness (AFR)

According to AFR, a decision making process must satisfy 4 conditions in order to be *legitimate and fair*:
1. **Publicity Condition**: Decisions that establish priorities (and their rationales) must be made in publicly accessible meetings. They should be transparent, and understandable to non-technical people.
2. **Relevance (or Full Acceptability) Condition**: The rationales for decisions should provide a *reasonable* explanation of why the selected priorities are the best way to realise algorithmic fairness.
3. **Revision and Appeals Condition**: There must be ongoing mechanisms for challenging decisions and resolving disputes over priority-setting or policy. 
4. **Regulative Condition**: There is public regulation that ensures conditions 1-3 are met.